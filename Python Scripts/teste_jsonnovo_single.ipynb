{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import json\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "records = []\n",
    "links_reportagem = []\n",
    "titulos = []\n",
    "data_hora = []\n",
    "links_noticia = []\n",
    "list_data_comentarios = []\n",
    "\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('C:/chromedriver/chromedriver.exe')\n",
    "\n",
    "def limpaArrays(array):\n",
    "    igual = set()\n",
    "    result = []\n",
    "    for item in array:\n",
    "        if item not in igual:\n",
    "            igual.add(item)\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "def gera_json():\n",
    "    \n",
    "    dados_comentarios = {\n",
    "        'comentario': records,\n",
    "        'data_comentario': list_data_comentarios\n",
    "    }\n",
    "        \n",
    "    Data = {\n",
    "        'link_noticia': links_noticia,\n",
    "        'titulo': titulos,\n",
    "        'data_hora': data_hora,\n",
    "        'comentarios': [dados_comentarios]\n",
    "    }\n",
    "    \n",
    "    json_dict = {}\n",
    "    data = []\n",
    "    \n",
    "    json_dict = OrderedDict([\n",
    "            ('link_noticia', links_noticia),\n",
    "            ('titulo', titulos),\n",
    "            ('data_hora', data_hora),\n",
    "            ('comentarios', [OrderedDict([\n",
    "                                       ('comentarios', records),\n",
    "                                       ('data_comentario', list_data_comentarios)])])\n",
    "           ])\n",
    "        \n",
    "\n",
    "    df = DataFrame(json_dict)\n",
    "    with open('pacoteteste_novo_json.json', 'w', encoding='utf-8') as file:\n",
    "        df.to_json(file, force_ascii=False, orient='index')\n",
    "    driver.quit()\n",
    "\n",
    "def pega_comentarios():\n",
    "    res = driver.execute_script('return document.documentElement.outerHTML')\n",
    "    soup = BeautifulSoup(res, 'html.parser') \n",
    "    link_noiticia = soup.find(\"link\",{\"itemprop\":\"mainEntityOfPage\"})\n",
    "    href_link_noticia = link_noiticia.get('href')\n",
    "    busca_titulo_noticia = soup.find(\"h1\",{\"class\":\"content-head__title\"})\n",
    "    titulo_noticia = busca_titulo_noticia.text\n",
    "    busca_data_hora = soup.find(\"time\",{\"itemprop\": \"datePublished\"})\n",
    "    data_hora_text = busca_data_hora.text\n",
    "    lista_recente = soup.find(\"div\",\"glbComentarios-lista glbComentarios-lista-recentes\")\n",
    "    lista = lista_recente.find(\"ul\", class_ = \"glbComentarios-lista-todos\")\n",
    "    if(lista):\n",
    "        li = lista.find_all(\"li\", {\"itemtype\":\"http://schema.org/UserComments\"})\n",
    "        for coments_ in li:\n",
    "            coments = coments_.find(\"p\", class_ = \"glbComentarios-texto-comentario\")\n",
    "            if(coments):\n",
    "                comentarios = coments.contents[0]\n",
    "                comentarios.strip()\n",
    "                records.append((comentarios)) \n",
    "            data_coments = coments_.find(\"abbr\", class_ = \"data cadastro\")\n",
    "            if(data_coments):\n",
    "                data_comentarios = data_coments.get('title')\n",
    "                list_data_comentarios.append((data_comentarios))\n",
    "        \n",
    "        data_hora.append((data_hora_text))\n",
    "        titulos.append((titulo_noticia))\n",
    "        links_noticia.append((href_link_noticia))\n",
    "    gera_json()\n",
    "                               \n",
    "def botao_respostas():\n",
    "    while True:\n",
    "        try:\n",
    "            mais_comentarios = driver.find_element_by_xpath(\"//*[@class='glbComentarios-lista glbComentarios-lista-recentes']/ul/li/div[1]/div/div[3]/button[not(contains(@style,'display: none'))]\")\n",
    "            time.sleep(3)\n",
    "            if(mais_comentarios.is_displayed()):\n",
    "                ActionChains(driver).move_to_element(mais_comentarios).click(mais_comentarios).perform()\n",
    "        except NoSuchElementException as e:\n",
    "            break\n",
    "    pega_comentarios()   \n",
    "\n",
    "def botao_carrega():\n",
    "    while True:\n",
    "        try:\n",
    "            carrega_mais = driver.find_element_by_xpath('//*[@id=\"boxComentarios\"]/div[4]/button')\n",
    "            time.sleep(2)\n",
    "            if(carrega_mais.is_displayed()):\n",
    "                ActionChains(driver).move_to_element(carrega_mais).click(carrega_mais).perform()\n",
    "            else:\n",
    "                break\n",
    "        except NoSuchElementException as e:\n",
    "            break\n",
    "    botao_respostas()\n",
    "     \n",
    "\n",
    "def busca_reportagens(url):\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    try:\n",
    "        box_comentarios = driver.find_element_by_id('boxComentarios')\n",
    "        driver.execute_script('arguments[0].scrollIntoView(true);', box_comentarios)\n",
    "    finally:\n",
    "        try:\n",
    "            element = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"glbComentarios\"))\n",
    "            )\n",
    "        finally:\n",
    "            botao_carrega()\n",
    "    \n",
    "\n",
    "def __init__(url):\n",
    "    busca_reportagens(url)\n",
    "    \n",
    "__init__('https://g1.globo.com/pop-arte/musica/rock-in-rio/2019/noticia/2019/09/29/witzel-diz-que-ha-genocidio-no-rj-e-que-vai-a-onu-pedir-punicoes-a-paises-vizinhos.ghtml')\n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
